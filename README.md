[ppt](./메타모델기반앙상블기법.pdf)


주제 선정 이유

문제 인식: Toss 앱 내 광고 클릭 예측 모델링 프로젝트를 진행하며, 기존 단일 모델의 성능을 넘어설 방법에 대한 고민 시작

해결 방안 발견: 메타 모델(Meta-model) 기반의 앙상블 기법이 성능 향상의 핵심이 될 수 있음을 발견

주제 구체화: 다양한 메타 모델 기법 중, 유사하면서도 차이가 있는 스태킹(Stacking)과 블렌딩(Blending)의 성능을 직접 비교·분석하여 최적의 모델링 전략을 탐구하고자 함


개념 설명

앙상블
여러 머신러닝 모델을 결합하여 각각의 모델에서 발생할 수 있는 오류를 줄이고
전체적인 예측 성능을 향상시키는 기법

앙상블 사용 이유
1. 성능향상: 단일 모델이 가질 수 있는 오류나 편향을 여러 모델을 결합함으로써 보완하여 전반적인 예측 정확도 향상

2. 과적합 방지: 여러 모델의 결과를 평균 내거나 투표함으로써 특정 데이터에 과도하게 최적화되는 것을 막아 모델의 안정성과 일반화 성능 향상



앙상블 기법 대표적인 종류
## 🌳 앙상블 (Ensemble) 기법 비교

| 구분 | 배깅 (Bagging) | 부스팅 (Boosting) | 스태킹 (Stacking) |
| :---: | :--- | :--- | :--- |
| **핵심 아이디어** | 병렬 학습 후 결과 집계 | 순차적 학습을 통한 오류 보완 | 여러 모델의 예측값을 활용한 메타 모델 학습 |
| **학습 방식** | 병렬 (Parallel) | 순차 (Sequential) | 병렬 (Base) → 단일 (Meta) |
| **대표 모델** | 랜덤 포레스트 | XGBoost, LightGBM | 기본 모델 + 메타 모델 |

메타모델
모델을 학습하는 모델

![메타 모델 아키텍처](./images/메타모델의 아키텍처 다이어그램.jpg)


스태킹 and 블렌딩

|-----스태킹-------|------블렌딩---------|
|----K-Fold Cross-Validation----|----Holdout-Validation------|
|---![스태킹 기반 메타모델 생성 과정](./images/스태킹.png)----|----![블렌딩 기반 메타모델 생성 과정](./images/블렌딩.png)----|

둘의 차이 
“메타모델을 학습시키기 위한 데이터를 어떻게 만드는가“


구현과정

사용한 데이터
kaggle의 "사기 거래 탐지" 데이터
175만 건
![사기 거래 탐지 데이터](https://www.kaggle.com/datasets/sanskar457/fraud-transaction-detection/data)

학습에 쓰인 컬럼을 사용하여
TX_AMOUNT,TX_TIME_SECONDS,TX_TIME_DAYS,TX_HOUR,TX_DAY_OF_WEEK

TX_FRAUD을 예측


사용 모델
기본모델 -> lightgbm, RandomForest
메타모델 -> Rogistic Regression
평가지표 -> f1-score, ROC-AUC, PR-AUC

기본모델 선정 이유
lgbm은 부스팅 계열로 과적합을 방지하는데 효과적
랜덤포레스트는 배깅 계열로 편향을 줄이는데 효과적

메타모델 선정 이유
단순함때문
선형모델은 기본 모델의 예측결과에 대한 최적의 가중치를 학습하는데 과적합 위험이 적고 안정적

평가지표 선정 이유
데이터의 불균형(합법거래:사기거래=86.5:13.5)
때문에 소수 클래스도 잘 탐지할 수 있도록 이 지표들 사용


ROC-AUC: 모델이 '정상(0)'과 '사기(1)'를 얼마나 잘 구별하는지에 대한 전반적인 능력 평가
모델의 판별 성능을 보여주므로 불균형 데이터 평가에 적합하다 판단하여 사용

AUPRC(PR-AUC): 이진 분류 모델의 성능을 평가하는 지표
소수클래스를 얼마나 정밀하게 잘 찾아내는지에 집중하는 지표