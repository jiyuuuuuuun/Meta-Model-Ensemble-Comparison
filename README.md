# 📈 메타모델 기반 앙상블 기법: Stacking vs. Blending 성능 비교

이 프로젝트는 메타 모델(Meta-model) 기반의 대표적인 앙상블 기법인 **스태킹(Stacking)** 과 **블렌딩(Blending)** 의 성능을 비교 분석하여 

주어진 문제에 대한 최적의 모델링 전략을 탐구하는 것을 목표로 합니다.

## 🎯 주제 선정 배경

데이콘의 Toss 앱 내 광고 클릭 예측 프로젝트를 진행하며 단일 모델의 성능을 뛰어넘는 방법에 대해 고민하게 되었습니다. 

그 해결책으로 **메타 모델 기반 앙상블 기법**이 성능 향상의 핵심이 될 수 있음을 발견했습니다. 

특히, 유사하면서도 명확한 차이가 있는 스태킹과 블렌딩의 성능을 직접 구현하고 비교해보고자 이 프로젝트를 시작하게 되었습니다.

---

## 📚 핵심 개념 정리

### 앙상블 (Ensemble)

> 여러 개의 머신러닝 모델을 결합하여 각 모델에서 발생할 수 있는 오류를 줄이고 전체적인 예측 성능을 향상시키는 기법입니다.

#### 앙상블을 사용하는 이유

1.  **성능 향상**: 단일 모델이 가질 수 있는 오류나 편향을 여러 모델을 결합함으로써 보완하여 전반적인 예측 정확도를 높입니다.
2.  **과적합 방지**: 여러 모델의 결과를 종합(평균, 투표 등)함으로써 특정 훈련 데이터에 과도하게 최적화되는 것을 막아 모델의 안정성과 일반화 성능을 향상시킵니다.

#### 대표적인 앙상블 기법

| 구분          | **배깅 (Bagging)** | **부스팅 (Boosting)** | **스태킹 (Stacking)** |
| :------------ | :----------------------------------------------- | :--------------------------------------------------- | :--------------------------------------------------- |
| **핵심 아이디어** | 병렬 학습 후 결과 집계                           | 순차적 학습을 통해 이전 모델의 오류를 보완             | 여러 모델의 예측값을 새로운 특성으로 활용해 메타 모델 학습 |
| **학습 방식** | 병렬 (Parallel)                                  | 순차 (Sequential)                                    | 병렬 (Base Models) → 단일 (Meta Model)               |
| **대표 모델** | 랜덤 포레스트 (Random Forest)                    | XGBoost, LightGBM                                    | 기본 모델 조합 + 메타 모델                             |

### 메타 모델 (Meta-model)

> **'모델을 학습하는 모델'**
> 
> 여러 기본 모델(Base Model)들의 예측 결과를 입력 데이터로 받아 최종 예측을 수행하는 상위 모델을 의미합니다.

<img alt="Image" src="https://github.com/user-attachments/assets/8cd3fda4-58d4-4b06-915a-43349fa61ffb" width="600" style="height:auto;" alt="Image">

---

## 🆚 스태킹 (Stacking) vs. 블렌딩 (Blending)

두 기법의 가장 핵심적인 차이는 **"메타 모델을 학습시키기 위한 훈련 데이터를 어떻게 만드는가"** 에 있습니다.

| **스태킹 (Stacking)** | **블렌딩 (Blending)** |
| :----------------------------------------------------- | :----------------------------------------------------- |
| **K-Fold 교차 검증 (Cross-Validation)** 방식      | **Hold-out** 방식                                 |
| 훈련 데이터 전체를 활용하여 메타 모델 학습 데이터를 생성 | 훈련 데이터를 일정 비율로 나누어(Train/Validation) 생성    |
| 데이터 손실이 적지만, 시간이 오래 걸릴 수 있음         | 구현이 간단하고 빠르지만, 메타 모델 학습 데이터가 적음 |
| [스태킹 기반 메타모델 생성 과정]<img width="1133" height="565" alt="Image" src="https://github.com/user-attachments/assets/54546414-8c69-48c5-9110-f0061dc876aa" />                   | [블렌딩 기반 메타모델 생성 과정]<img width="824" height="528" alt="Image" src="https://github.com/user-attachments/assets/89832e7d-c050-4695-a171-ebae2aed54df" />                    |

---

## ⚙️ 구현 과정

### 1. 데이터셋

* **데이터**: Kaggle의 [**사기 거래 탐지 (Fraud Transaction Detection)**](https://www.kaggle.com/datasets/sanskar457/fraud-transaction-detection/) 데이터
* **데이터 크기**: 약 175만 건
* **주요 특징**: `TX_AMOUNT`, `TX_TIME_SECONDS`, `TX_TIME_DAYS`, `TX_HOUR`, `TX_DAY_OF_WEEK`
* **예측 목표 (Target)**: `TX_FRAUD` (사기 여부)
* **데이터 불균형**: 합법 거래와 사기 거래의 비율이 **86.5 : 13.5**로 불균형한 데이터

### 2. 사용 모델

* **기본 모델 (Base Models)**
    * **LightGBM**: 부스팅 계열로, 과적합 방지에 효과적이고 빠른 속도를 가집니다.
    * **RandomForest**: 배깅 계열로, 모델의 편향을 줄이고 안정적인 성능을 보입니다.
* **메타 모델 (Meta Model)**
    * **Logistic Regression**: 기본 모델들의 예측 결과에 대한 최적의 가중치를 학습하는 데 있어, 모델 자체가 단순하여 과적합 위험이 적고 안정적이기 때문에 선정했습니다.

### 3. 평가지표

데이터가 불균형하기 때문에, 소수 클래스(사기 거래)를 얼마나 잘 탐지하는지를 종합적으로 평가하기 위해 다음 지표를 선정했습니다.

* **F1-Score**: 정밀도(Precision)와 재현율(Recall)의 조화 평균으로, 불균형 데이터에서 모델 성능을 정확하게 평가할 수 있습니다.
* **ROC-AUC**: 모델이 '정상(0)'과 '사기(1)'를 얼마나 잘 구별하는지에 대한 전반적인 판별 능력을 평가합니다.
* **PR-AUC (AUPRC)**: 소수 클래스를 얼마나 정밀하게 잘 찾아내는지에 더 집중하는 지표로, 불균형 데이터 평가에 매우 중요합니다.

